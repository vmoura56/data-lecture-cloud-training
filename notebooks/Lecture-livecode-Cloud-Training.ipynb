{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The livecodes of the lecture are based on the code used by the students during the challenges.\n",
    "\n",
    "We will use the **data-lecture-cloud-training** challenge for all the livecodes of the lecture.\n",
    "\n",
    "Myriad batches:\n",
    "\n",
    "``` bash\n",
    "cd data-lecture-cloud-training\n",
    "```\n",
    "\n",
    "Legacy batches:\n",
    "\n",
    "``` bash\n",
    "cd data-challenges/07-ML-Ops/02-Cloud-training/00-Lecture-livecode\n",
    "```\n",
    "\n",
    "Download data:\n",
    "\n",
    "``` bash\n",
    "curl https://storage.googleapis.com/datascience-mlops/taxi-fare-ny/train_10k.csv > ~/.lewagon/mlops/data/raw/train_10k.csv\n",
    "curl https://storage.googleapis.com/datascience-mlops/taxi-fare-ny/val_10k.csv > ~/.lewagon/mlops/data/raw/val_10k.csv\n",
    "```\n",
    "\n",
    "Then use VSCode:\n",
    "\n",
    "``` bash\n",
    "code .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the model trains:\n",
    "\n",
    "``` bash\n",
    "make run_preprocess run_train\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "equivalent to running **interface/main.py** with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    preprocess()\n",
    "    preprocess(source_type='val')\n",
    "    train()\n",
    "    # pred()\n",
    "    # evaluate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up `direnv` to manage environment variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install using instructions for your machine [in direnv docs](https://direnv.net/docs/installation.html)\n",
    "\n",
    "1. After installation, add `direnv` to the list of oh-my-zsh plugins in your `~/.zshrc` (run `zsh` or open a new terminal window in order to apply the change)\n",
    "2. If `direnv` does not load in the shell you can run `eval \"$(direnv hook zsh)\"` (add it to the `~/.zshrc` as well)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**model_target/local_model.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_local_model(model, suffix):\n",
    "\n",
    "    if model:\n",
    "\n",
    "        model_path = os.path.join(os.environ.get(\"LOCAL_REGISTRY_PATH\"), \"models\",\n",
    "                                  suffix + \".pickle\")\n",
    "\n",
    "        print(f\"- model path: {model_path}\")\n",
    "\n",
    "        model.save(model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**model_target/cloud_model.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cloud_model(model, suffix):\n",
    "\n",
    "    print(\"TODO: save model in the cloud ðŸ§¬\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**data_sources/cloud_data.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cloud_chunk(path,\n",
    "                    index,\n",
    "                    chunk_size,\n",
    "                    dtypes,\n",
    "                    columns):\n",
    "\n",
    "    print(\"TODO: get cloud chunk ðŸ§©\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ml_logic/registry.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from taxifare.model_target.local_model import save_local_model\n",
    "from taxifare.model_target.cloud_model import save_cloud_model\n",
    "\n",
    "        if os.environ[\"MODEL_TARGET\"] == \"local\":\n",
    "            save_local_model(model, suffix)\n",
    "        elif os.environ[\"MODEL_TARGET\"] == \"cloud\":\n",
    "            save_cloud_model(model, suffix)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid .env config for model: {os.environ['MODEL_TARGET']} ðŸ¤•\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ml_logic/data.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from taxifare.data_sources.cloud_data import get_cloud_chunk\n",
    "\n",
    "    if os.environ[\"DATA_SOURCE\"] == \"local\":\n",
    "        chunk_df = get_pandas_chunk(path=source_name,\n",
    "                                    index=index,\n",
    "                                    chunk_size=chunk_size,\n",
    "                                    dtypes=dtypes,\n",
    "                                    columns=columns)\n",
    "    elif os.environ[\"DATA_SOURCE\"] == \"cloud\":\n",
    "        chunk_df = get_cloud_chunk(table=source_name,\n",
    "                                   index=index,\n",
    "                                   chunk_size=chunk_size,\n",
    "                                   dtypes=dtypes)\n",
    "    else:\n",
    "        raise NameError(f\"Invalid .env conf for data: {os.environ['DATA_SOURCE']} ðŸ˜¬\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model in the cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**raw code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "BUCKET_NAME = \"my-bucket\"\n",
    "\n",
    "storage_filename = \"models/random_forest_model.joblib\"\n",
    "local_filename = \"model.joblib\"\n",
    "\n",
    "client = storage.Client()\n",
    "bucket = client.bucket(BUCKET_NAME)\n",
    "blob = bucket.blob(storage_filename)\n",
    "blob.upload_from_filename(local_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**model_target/cloud_model.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def save_cloud_model(model, suffix):\n",
    "\n",
    "    # save the model\n",
    "    if model:\n",
    "\n",
    "        model_path = os.path.join(os.environ.get(\"LOCAL_REGISTRY_PATH\"), \"models\",\n",
    "                                  suffix + \".pickle\")\n",
    "\n",
    "        model.save(model_path)\n",
    "\n",
    "        # list model files\n",
    "        files = glob.glob(f\"{model_path}/**/*.*\", recursive=True)\n",
    "\n",
    "        for file in files:\n",
    "            storage_filename = file[17:]\n",
    "\n",
    "            client = storage.Client()\n",
    "            bucket = client.bucket(os.environ[\"BUCKET_NAME\"])\n",
    "            blob = bucket.blob(storage_filename)\n",
    "            blob.upload_from_filename(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data in the cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**raw code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client()\n",
    "rows = client.list_rows(table, start_index=index, max_results=chunk_size)\n",
    "big_query_df = rows.to_dataframe()\n",
    "\n",
    "if big_query_df.shape[0] == 0:\n",
    "    return None  # end of data\n",
    "\n",
    "big_query_df = big_query_df.astype(dtypes)\n",
    "\n",
    "return big_query_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**data_sources/cloud_data.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "def get_cloud_chunk(table, index, chunk_size, dtypes):\n",
    "\n",
    "    table = f\"{os.environ['PROJECT']}.{os.environ['DATASET']}.{table}\"\n",
    "\n",
    "    client = bigquery.Client()\n",
    "\n",
    "    rows = client.list_rows(table, start_index=index, max_results=chunk_size)\n",
    "\n",
    "    big_query_df = rows.to_dataframe()\n",
    "\n",
    "    if big_query_df.shape[0] == 0:\n",
    "        return None  # end of data\n",
    "\n",
    "    big_query_df = big_query_df.astype(dtypes)\n",
    "\n",
    "    print(f\"Data loaded from BQ ðŸ”¥\")\n",
    "    print(big_query_df.head())\n",
    "\n",
    "    return big_query_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training in the cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup a VM by following the **training in the cloud** challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code essentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "BUCKET_NAME = \"my-bucket\"\n",
    "\n",
    "storage_filename = \"models/random_forest_model.joblib\"\n",
    "local_filename = \"model.joblib\"\n",
    "\n",
    "client = storage.Client()\n",
    "bucket = client.bucket(BUCKET_NAME)\n",
    "blob = bucket.blob(storage_filename)\n",
    "blob.upload_from_filename(local_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client()\n",
    "rows = client.list_rows(table, start_index=index, max_results=chunk_size)\n",
    "big_query_df = rows.to_dataframe()\n",
    "\n",
    "if big_query_df.shape[0] == 0:\n",
    "    return None  # end of data\n",
    "\n",
    "big_query_df = big_query_df.astype(dtypes)\n",
    "\n",
    "return big_query_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
